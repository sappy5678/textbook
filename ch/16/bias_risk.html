
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>16.1. Risk and Loss Minimization &#8212; Principles and Techniques of Data Science</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="16.2. Model Bias and Variance" href="bias_modeling.html" />
    <link rel="prev" title="16. The Bias-Variance Tradeoff" href="bias_intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  
  <h1 class="site-logo" id="site-title">Principles and Techniques of Data Science</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prereqs.html">
   Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notation.html">
   Notation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../01/lifecycle_intro.html">
   1. The Data Science Lifecycle
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02/design_intro.html">
   2. Data Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03/pandas_intro.html">
   3. Working with Tabular Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04/eda_intro.html">
   4. Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05/cleaning_intro.html">
   5. Data Cleaning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06/viz_intro.html">
   6. Data Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07/web_intro.html">
   7. Web Technologies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08/text_intro.html">
   8. Working with Text
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09/sql_intro.html">
   9. Relational Databases and SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10/pca_intro.html">
   10. Dimensionality Reduction and PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11/modeling_intro.html">
   11. Modeling and Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../12/gradient_descent.html">
   12. Gradient Descent and Numerical Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../13/prob_and_gen.html">
   13. Probability and Generalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../14/linear_models.html">
   14. Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../15/feature_engineering.html">
   15. Feature Engineering
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="bias_intro.html">
   16. The Bias-Variance Tradeoff
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     16.1. Risk and Loss Minimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bias_modeling.html">
     16.2. Model Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bias_cv.html">
     16.3. Cross-Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../17/reg_intro.html">
   17. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../18/classification_intro.html">
   18. Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../19/hyp_intro.html">
   19. Statistical Inference
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../20/vector_space_review.html">
   Vector Space Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../21/ref_intro.html">
   Reference Tables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../22/contributors.html">
   Contributors
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/ch/16/bias_risk.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/ch/16/bias_risk.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#risk">
   16.1.1. Risk
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-risk">
   16.1.2. Empirical Risk
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   16.1.3. Summary
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">df_interact</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Outputs sliders that show rows and columns of df</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="n">row</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row</span><span class="p">:</span><span class="n">row</span> <span class="o">+</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">col</span><span class="p">:</span><span class="n">col</span> <span class="o">+</span> <span class="n">ncols</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">ncols</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">interact</span><span class="p">(</span><span class="n">peek</span><span class="p">,</span>
                 <span class="n">row</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">nrows</span><span class="p">),</span>
                 <span class="n">col</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="n">ncols</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(</span><span class="si">{}</span><span class="s1"> rows, </span><span class="si">{}</span><span class="s1"> columns) total&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="risk-and-loss-minimization">
<h1><span class="section-number">16.1. </span>Risk and Loss Minimization<a class="headerlink" href="#risk-and-loss-minimization" title="Permalink to this headline">¶</a></h1>
<p>In order to make predictions using data, we define a model, select a loss function across the entire dataset, and fit the model’s parameters by minimizing the loss. For example, to conduct least squares linear regression, we select the model:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
f_\hat{\theta} (x) &amp;= \hat{\theta} \cdot x
\end{aligned}
\]</div>
<p>And the loss function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L(\hat{\theta}, X, y)
&amp;= \frac{1}{n} \sum_{i}(y_i - f_\hat{\theta} (X_i))^2\\
\end{aligned}
\end{split}\]</div>
<p>As before, we use <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> as our vector of model parameters, <span class="math notranslate nohighlight">\( x \)</span> as a vector containing a row of a data matrix <span class="math notranslate nohighlight">\( X \)</span>, and <span class="math notranslate nohighlight">\( y \)</span> as our vector of observed values to predict. <span class="math notranslate nohighlight">\( X_i \)</span> is the <span class="math notranslate nohighlight">\(i\)</span>’th row of <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y_i \)</span> is the <span class="math notranslate nohighlight">\(i\)</span>’th entry of y.</p>
<p>Observe that our lost function across the dataset is the average of the loss function values for each row of our data. If we define the squared loss function:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\ell(y_i, f_\hat{\theta} (x))
&amp;= (y_i - f_\hat{\theta} (x))^2
\end{aligned}
\]</div>
<p>Then we may rewrite our average loss function more simply:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
L(\hat{\theta}, X, y)
&amp;= \frac{1}{n} \sum_{i} \ell(y_i, f_\hat{\theta} (X_i))
\end{aligned}
\]</div>
<p>The expression above abstracts over the specific loss function; regardless of the loss function we choose, our overall loss is the average loss.</p>
<p>By minimizing the average loss, we select the model parameters that best fit our observed dataset. Thus far, we have refrained from making statements about the population that generated the dataset. In reality, however, we are quite interested in making good predictions on the entire population, not just our data that we have already seen.</p>
<div class="section" id="risk">
<h2><span class="section-number">16.1.1. </span>Risk<a class="headerlink" href="#risk" title="Permalink to this headline">¶</a></h2>
<p>If our observed dataset <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span> are drawn at random from a given population, our observed data are random variables. If our observed data are random variables, our model parameters are also random variables—each time we collect a new set of data and fit a model, the parameters of the model <span class="math notranslate nohighlight">\( f_\hat{\theta} (x) \)</span> will be slightly different.</p>
<p>Suppose we draw one more input-output pair <span class="math notranslate nohighlight">\(z, \gamma \)</span> from our population at random. The loss that our model produces on this value is:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\ell(\gamma, f_\hat{\theta} (z))
\end{aligned}
\]</div>
<p>Notice that this loss is a random variable; the loss changes for different sets of observed data <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span> and different points <span class="math notranslate nohighlight">\(z, \gamma \)</span> from our population.</p>
<p>The <strong>risk</strong> for a model <span class="math notranslate nohighlight">\( f_\hat{\theta} \)</span> is the expected value of the loss above for all training data <span class="math notranslate nohighlight">\( X \)</span>, <span class="math notranslate nohighlight">\( y \)</span> and all points <span class="math notranslate nohighlight">\( z\)</span>, <span class="math notranslate nohighlight">\( \gamma \)</span> in the population:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
R(f_\hat{\theta}(x)) = \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ]
\end{aligned}
\]</div>
<p>Notice that the risk is an expectation of a random variable and is thus <em>not</em> random itself. The expected value of fair six-sided die rolls is 3.5 even though the rolls themselves are random.</p>
<p>The risk above is sometimes called the <strong>true risk</strong> because it tells how a model does on the entire population. If we could compute the true risk for all models, we can simply pick the model with the least risk and know with certainty that the model will perform better in the long run than all other models on our choice of loss function.</p>
</div>
<div class="section" id="empirical-risk">
<h2><span class="section-number">16.1.2. </span>Empirical Risk<a class="headerlink" href="#empirical-risk" title="Permalink to this headline">¶</a></h2>
<p>Reality, however, is not so kind. If we substitute in the definition of expectation into the formula for the true risk, we get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
R(f_\hat{\theta})
&amp;= \mathbb{E}[ \ell(\gamma, f_\hat{\theta} (z)) ] \\
&amp;= \sum_\gamma \sum_z \ell(\gamma, f_\hat{\theta} (z)) P(\gamma, z) \\
\end{aligned}
\end{split}\]</div>
<p>To further simplify this expression, we need to know <span class="math notranslate nohighlight">\( P(\gamma, z)  \)</span>, the global probability distribution of observing any point in the population. Unfortunately, this is not so easy. Suppose we are trying to predict the tip amount based on the size of the table. What is the probability that a table of three people gives a tip of $14.50? If we knew the distribution of points exactly, we wouldn’t have to collect data or fit a model—we would already know the most likely tip amount for any given table.</p>
<p>Although we do not know the exact distribution of the population, we can approximate it using the observed dataset <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span>. If <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span> are drawn at random from our population, the distribution of points in <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span> is similar to the population distribution. Thus, we treat <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( y \)</span> as our population. Then, the probability that any input-output pair <span class="math notranslate nohighlight">\( X_i \)</span>, <span class="math notranslate nohighlight">\( y_i \)</span> appears is <span class="math notranslate nohighlight">\( \frac{1}{n} \)</span> since each pair appears once out of <span class="math notranslate nohighlight">\( n \)</span> points total.</p>
<p>This allows us to calculate the <strong>empirical risk</strong>, an approximation for the true risk:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat R(f_\hat{\theta})
&amp;= \mathbb{E}[ \ell(y_i, f_\hat{\theta} (X_i)) ] \\
&amp;= \sum_{i=1}^n \ell(y_i, f_\hat{\theta} (X_i)) \frac{1}{n} \\
&amp;= \frac{1}{n} \sum_{i=1}^n \ell(y_i, f_\hat{\theta} (X_i)) 
\end{aligned}
\end{split}\]</div>
<p>If our dataset is large and the data are drawn at random from the population, the empirical risk <span class="math notranslate nohighlight">\( \hat R(f_\hat{\theta}) \)</span> is close to the true risk <span class="math notranslate nohighlight">\( R(f_\hat{\theta}) \)</span>. This allows us to pick the model that minimizes the empirical risk.</p>
<p>Notice that this expression is the average loss function at the start of the section! By minimizing the average loss, we also minimize the empirical risk. This explains why we often use the average loss as our overall loss function instead of the maximum loss, for example.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">16.1.3. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>The true risk of a prediction model describes the overall long-run loss that the model will produce for the population. Since we typically cannot calculate the true risk directly, we calculate the empirical risk instead and use the empirical risk to find an appropriate model for prediction. Because the empirical risk is the average loss on the observed dataset, we often minimize the average loss when fitting models.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch/16"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="bias_intro.html" title="previous page"><span class="section-number">16. </span>The Bias-Variance Tradeoff</a>
    <a class='right-next' id="next-link" href="bias_modeling.html" title="next page"><span class="section-number">16.2. </span>Model Bias and Variance</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Sam Lau, Joey Gonzalez, and Deb Nolan<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-113006011-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>